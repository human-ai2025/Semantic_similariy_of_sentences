{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_Quora_Preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r763jIis6G4"
      },
      "source": [
        "## Importing Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xf-BDQnAuG89",
        "outputId": "387f4ba0-9562-45a7-bbe9-832fe5102805"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omBYR9Pms6G6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "outputId": "ffc66b8e-8584-4ecb-9613-5e7e7f1926bf"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from subprocess import check_output\n",
        "%matplotlib inline\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "import plotly.tools as tls\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import distance\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "# This package is used for finding longest common subsequence between two strings\n",
        "# you can write your own dp code for this\n",
        "import distance\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "from os import path"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxr6UbxtpqOL",
        "outputId": "2b033958-408f-4388-fd5b-0d9418adf42f"
      },
      "source": [
        "##mount drive for data\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7DXrx3OpzGg",
        "outputId": "8bbfaeaf-e19a-4e32-9bb5-795b15bf009b"
      },
      "source": [
        "#setup the path\r\n",
        "%cd /content/drive/MyDrive/Quora"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1OWZoiQDvAvgOa-IUnEQ-6QKSEp_pw1XO/Quora\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSq37fjBs6HE"
      },
      "source": [
        "#https://stackoverflow.com/questions/12468179/unicodedecodeerror-utf8-codec-cant-decode-byte-0x9c\n",
        "if os.path.isfile('df_fe_without_preprocessing_train.csv'):\n",
        "    df = pd.read_csv(\"df_fe_without_preprocessing_train.csv\",encoding='latin-1')\n",
        "    df = df.fillna('')\n",
        "    df.head()\n",
        "else:\n",
        "    print(\"get df_fe_without_preprocessing_train.csv from run the previous notebook\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL-KVVkYs6HM",
        "outputId": "45a91ebe-26c8-47ed-f2f3-b9eef725af8a"
      },
      "source": [
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>freq_qid1</th>\n",
              "      <th>freq_qid2</th>\n",
              "      <th>q1len</th>\n",
              "      <th>q2len</th>\n",
              "      <th>q1_n_words</th>\n",
              "      <th>q2_n_words</th>\n",
              "      <th>word_Common</th>\n",
              "      <th>word_Total</th>\n",
              "      <th>word_share</th>\n",
              "      <th>freq_q1+q2</th>\n",
              "      <th>freq_q1-q2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>66</td>\n",
              "      <td>57</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "      <td>10.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>88</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>4.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  qid2                                          question1  \\\n",
              "0   0     1     2  What is the step by step guide to invest in sh...   \n",
              "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
              "\n",
              "                                           question2  is_duplicate  freq_qid1  \\\n",
              "0  What is the step by step guide to invest in sh...             0          1   \n",
              "1  What would happen if the Indian government sto...             0          4   \n",
              "\n",
              "   freq_qid2  q1len  q2len  q1_n_words  q2_n_words  word_Common  word_Total  \\\n",
              "0          1     66     57          14          12         10.0        23.0   \n",
              "1          1     51     88           8          13          4.0        20.0   \n",
              "\n",
              "   word_share  freq_q1+q2  freq_q1-q2  \n",
              "0    0.434783           2           0  \n",
              "1    0.200000           5           3  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWQAzMyWs6HU"
      },
      "source": [
        "<h2> 3.4 Preprocessing of Text </h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2_6a1Ils6HV"
      },
      "source": [
        "- Preprocessing:\n",
        "    - Removing html tags \n",
        "    - Removing Punctuations\n",
        "    - Performing stemming\n",
        "    - Removing Stopwords\n",
        "    - Expanding contractions etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgE3QuLws6HW"
      },
      "source": [
        "# To get the results in 4 decemal points\n",
        "SAFE_DIV = 0.0001 \n",
        "\n",
        "STOP_WORDS = stopwords.words(\"english\")\n",
        "\n",
        "\n",
        "def preprocess(x):\n",
        "    x = str(x).lower()\n",
        "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
        "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
        "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
        "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
        "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
        "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
        "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
        "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
        "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
        "    x = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", x)\n",
        "    x = re.sub(r\"e - mail\", \"email\", x)\n",
        "    \n",
        "    \n",
        "    porter = PorterStemmer()\n",
        "    pattern = re.compile('\\W')\n",
        "    \n",
        "    if type(x) == type(''):\n",
        "        x = re.sub(pattern, ' ', x)\n",
        "    \n",
        "    \n",
        "    if type(x) == type(''):\n",
        "        x = porter.stem(x)\n",
        "        example1 = BeautifulSoup(x)\n",
        "        x = example1.get_text()\n",
        "               \n",
        "    \n",
        "    return x\n",
        "    "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMuIfNgyt4wQ"
      },
      "source": [
        "def text_preprocessing(df):\r\n",
        "    # preprocessing each question\r\n",
        "    df[\"question1\"] = df[\"question1\"].fillna(\"\").apply(preprocess)\r\n",
        "    df[\"question2\"] = df[\"question2\"].fillna(\"\").apply(preprocess)\r\n",
        "\r\n",
        "    return df"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLTDwf-Gujtt",
        "outputId": "c982b11e-41ec-4eff-e6cc-f64a99b2dc70"
      },
      "source": [
        "if os.path.isfile('df_with_preprocessing_train.csv'):\r\n",
        "    df = pd.read_csv(\"df_with_preprocessing_train.csv\",encoding='latin-1')\r\n",
        "    df.fillna('')\r\n",
        "else:\r\n",
        "    print(\"Preprocessing Text:\")\r\n",
        "    df = pd.read_csv(\"train.csv\")\r\n",
        "    df = text_preprocessing(df)\r\n",
        "    df.to_csv(\"df_with_preprocessing_train.csv\", index=False)\r\n",
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing Text:\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}